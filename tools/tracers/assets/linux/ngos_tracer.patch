diff --git a/arch/x86/boot/compressed/eboot.c b/arch/x86/boot/compressed/eboot.c
index c3e869e..6046cde 100644
--- a/arch/x86/boot/compressed/eboot.c
+++ b/arch/x86/boot/compressed/eboot.c
@@ -28,7 +28,7 @@ __pure const struct efi_config *__efi_early(void)
 }
 
 #define BOOT_SERVICES(bits)						\
-static void setup_boot_services##bits(struct efi_config *c)		\
+void setup_boot_services##bits(struct efi_config *c)		\
 {									\
 	efi_system_table_##bits##_t *table;				\
 									\
@@ -108,7 +108,7 @@ void efi_char16_printk(efi_system_table_t *table, efi_char16_t *str)
 		       efi_early->text_output, str);
 }
 
-static efi_status_t
+efi_status_t
 __setup_efi_pci32(efi_pci_io_protocol_32 *pci, struct pci_setup_rom **__rom)
 {
 	struct pci_setup_rom *rom = NULL;
@@ -171,7 +171,7 @@ __setup_efi_pci32(efi_pci_io_protocol_32 *pci, struct pci_setup_rom **__rom)
 	return status;
 }
 
-static void
+void
 setup_efi_pci32(struct boot_params *params, void **pci_handle,
 		unsigned long size)
 {
@@ -216,7 +216,7 @@ setup_efi_pci32(struct boot_params *params, void **pci_handle,
 	}
 }
 
-static efi_status_t
+efi_status_t
 __setup_efi_pci64(efi_pci_io_protocol_64 *pci, struct pci_setup_rom **__rom)
 {
 	struct pci_setup_rom *rom;
@@ -278,7 +278,7 @@ __setup_efi_pci64(efi_pci_io_protocol_64 *pci, struct pci_setup_rom **__rom)
 
 }
 
-static void
+void
 setup_efi_pci64(struct boot_params *params, void **pci_handle,
 		unsigned long size)
 {
@@ -332,7 +332,7 @@ setup_efi_pci64(struct boot_params *params, void **pci_handle,
  * just didn't find any PCI devices, but there's no way to tell outside
  * the context of the call.
  */
-static void setup_efi_pci(struct boot_params *params)
+void setup_efi_pci(struct boot_params *params)
 {
 	efi_status_t status;
 	void **pci_handle = NULL;
@@ -370,7 +370,7 @@ static void setup_efi_pci(struct boot_params *params)
 	efi_call_early(free_pool, pci_handle);
 }
 
-static void retrieve_apple_device_properties(struct boot_params *boot_params)
+void retrieve_apple_device_properties(struct boot_params *boot_params)
 {
 	efi_guid_t guid = APPLE_PROPERTIES_PROTOCOL_GUID;
 	struct setup_data *data, *new;
@@ -421,7 +421,7 @@ static void retrieve_apple_device_properties(struct boot_params *boot_params)
 	}
 }
 
-static void setup_quirks(struct boot_params *boot_params)
+void setup_quirks(struct boot_params *boot_params)
 {
 	efi_char16_t const apple[] = { 'A', 'p', 'p', 'l', 'e', 0 };
 	efi_char16_t *fw_vendor = (efi_char16_t *)(unsigned long)
@@ -433,7 +433,7 @@ static void setup_quirks(struct boot_params *boot_params)
 	}
 }
 
-static efi_status_t
+efi_status_t
 setup_uga32(void **uga_handle, unsigned long size, u32 *width, u32 *height)
 {
 	struct efi_uga_draw_protocol *uga = NULL, *first_uga;
@@ -478,7 +478,7 @@ setup_uga32(void **uga_handle, unsigned long size, u32 *width, u32 *height)
 	return status;
 }
 
-static efi_status_t
+efi_status_t
 setup_uga64(void **uga_handle, unsigned long size, u32 *width, u32 *height)
 {
 	struct efi_uga_draw_protocol *uga = NULL, *first_uga;
@@ -526,7 +526,7 @@ setup_uga64(void **uga_handle, unsigned long size, u32 *width, u32 *height)
 /*
  * See if we have Universal Graphics Adapter (UGA) protocol
  */
-static efi_status_t setup_uga(struct screen_info *si, efi_guid_t *uga_proto,
+efi_status_t setup_uga(struct screen_info *si, efi_guid_t *uga_proto,
 			      unsigned long size)
 {
 	efi_status_t status;
@@ -723,7 +723,7 @@ struct boot_params *make_boot_params(struct efi_config *c)
 	return NULL;
 }
 
-static void add_e820ext(struct boot_params *params,
+void add_e820ext(struct boot_params *params,
 			struct setup_data *e820ext, u32 nr_entries)
 {
 	struct setup_data *data;
@@ -745,7 +745,7 @@ static void add_e820ext(struct boot_params *params,
 		params->hdr.setup_data = (unsigned long)e820ext;
 }
 
-static efi_status_t setup_e820(struct boot_params *params,
+efi_status_t setup_e820(struct boot_params *params,
 			       struct setup_data *e820ext, u32 e820ext_size)
 {
 	struct boot_e820_entry *entry = params->e820_table;
@@ -843,7 +843,7 @@ static efi_status_t setup_e820(struct boot_params *params,
 	return EFI_SUCCESS;
 }
 
-static efi_status_t alloc_e820ext(u32 nr_desc, struct setup_data **e820ext,
+efi_status_t alloc_e820ext(u32 nr_desc, struct setup_data **e820ext,
 				  u32 *e820ext_size)
 {
 	efi_status_t status;
@@ -915,7 +915,7 @@ static efi_status_t exit_boot_func(efi_system_table_t *sys_table_arg,
 	return EFI_SUCCESS;
 }
 
-static efi_status_t exit_boot(struct boot_params *boot_params,
+efi_status_t exit_boot(struct boot_params *boot_params,
 			      void *handle, bool is64)
 {
 	unsigned long map_sz, key, desc_size, buff_size;
diff --git a/arch/x86/boot/compressed/kaslr.c b/arch/x86/boot/compressed/kaslr.c
index 91f27ab..de8f8a5 100644
--- a/arch/x86/boot/compressed/kaslr.c
+++ b/arch/x86/boot/compressed/kaslr.c
@@ -49,7 +49,7 @@ extern unsigned long get_cmd_line_ptr(void);
 static const char build_str[] = UTS_RELEASE " (" LINUX_COMPILE_BY "@"
 		LINUX_COMPILE_HOST ") (" LINUX_COMPILER ") " UTS_VERSION;
 
-static unsigned long rotate_xor(unsigned long hash, const void *area,
+unsigned long rotate_xor(unsigned long hash, const void *area,
 				size_t size)
 {
 	size_t i;
@@ -65,7 +65,7 @@ static unsigned long rotate_xor(unsigned long hash, const void *area,
 }
 
 /* Attempt to create a simple but unpredictable starting entropy. */
-static unsigned long get_boot_seed(void)
+unsigned long get_boot_seed(void)
 {
 	unsigned long hash = 0;
 
@@ -105,7 +105,7 @@ enum mem_avoid_index {
 
 static struct mem_vector mem_avoid[MEM_AVOID_MAX];
 
-static bool mem_overlaps(struct mem_vector *one, struct mem_vector *two)
+bool mem_overlaps(struct mem_vector *one, struct mem_vector *two)
 {
 	/* Item one is entirely before item two. */
 	if (one->start + one->size <= two->start)
@@ -125,7 +125,7 @@ char *skip_spaces(const char *str)
 #include "../../../../lib/ctype.c"
 #include "../../../../lib/cmdline.c"
 
-static int
+int
 parse_memmap(char *p, unsigned long long *start, unsigned long long *size)
 {
 	char *oldp;
@@ -165,7 +165,7 @@ parse_memmap(char *p, unsigned long long *start, unsigned long long *size)
 	return -EINVAL;
 }
 
-static void mem_avoid_memmap(char *str)
+void mem_avoid_memmap(char *str)
 {
 	static int i;
 	int rc;
@@ -204,7 +204,7 @@ static void mem_avoid_memmap(char *str)
 		memmap_too_large = true;
 }
 
-static int handle_mem_memmap(void)
+int handle_mem_memmap(void)
 {
 	char *args = (char *)get_cmd_line_ptr();
 	size_t len = strlen((char *)args);
@@ -329,7 +329,7 @@ static int handle_mem_memmap(void)
  * they can be merged, resulting in: [input, output+init_size) which
  * becomes the MEM_AVOID_ZO_RANGE below.
  */
-static void mem_avoid_init(unsigned long input, unsigned long input_size,
+void mem_avoid_init(unsigned long input, unsigned long input_size,
 			   unsigned long output)
 {
 	unsigned long init_size = boot_params->hdr.init_size;
@@ -388,7 +388,7 @@ static void mem_avoid_init(unsigned long input, unsigned long input_size,
  * Does this memory vector overlap a known avoided area? If so, record the
  * overlap region with the lowest address.
  */
-static bool mem_avoid_overlap(struct mem_vector *img,
+bool mem_avoid_overlap(struct mem_vector *img,
 			      struct mem_vector *overlap)
 {
 	int i;
@@ -438,7 +438,7 @@ static unsigned long slot_max;
 
 static unsigned long slot_area_index;
 
-static void store_slot_info(struct mem_vector *region, unsigned long image_size)
+void store_slot_info(struct mem_vector *region, unsigned long image_size)
 {
 	struct slot_area slot_area;
 
@@ -455,7 +455,7 @@ static void store_slot_info(struct mem_vector *region, unsigned long image_size)
 	}
 }
 
-static unsigned long slots_fetch_random(void)
+unsigned long slots_fetch_random(void)
 {
 	unsigned long slot;
 	int i;
@@ -465,6 +465,7 @@ static unsigned long slots_fetch_random(void)
 		return 0;
 
 	slot = kaslr_get_random_long("Physical") % slot_max;
+	slot = 0;
 
 	for (i = 0; i < slot_area_index; i++) {
 		if (slot >= slot_areas[i].num) {
@@ -479,7 +480,7 @@ static unsigned long slots_fetch_random(void)
 	return 0;
 }
 
-static void process_e820_entry(struct boot_e820_entry *entry,
+void process_e820_entry(struct boot_e820_entry *entry,
 			       unsigned long minimum,
 			       unsigned long image_size)
 {
@@ -562,7 +563,7 @@ static void process_e820_entry(struct boot_e820_entry *entry,
 	}
 }
 
-static unsigned long find_random_phys_addr(unsigned long minimum,
+unsigned long find_random_phys_addr(unsigned long minimum,
 					   unsigned long image_size)
 {
 	int i;
@@ -590,7 +591,7 @@ static unsigned long find_random_phys_addr(unsigned long minimum,
 	return slots_fetch_random();
 }
 
-static unsigned long find_random_virt_addr(unsigned long minimum,
+unsigned long find_random_virt_addr(unsigned long minimum,
 					   unsigned long image_size)
 {
 	unsigned long slots, random_addr;
@@ -671,4 +672,5 @@ void choose_random_location(unsigned long input,
 	if (IS_ENABLED(CONFIG_X86_64))
 		random_addr = find_random_virt_addr(LOAD_PHYSICAL_ADDR, output_size);
 	*virt_addr = random_addr;
+	*virt_addr = 0x1000000;
 }
diff --git a/arch/x86/boot/compressed/misc.c b/arch/x86/boot/compressed/misc.c
index c14217c..cb4d150 100644
--- a/arch/x86/boot/compressed/misc.c
+++ b/arch/x86/boot/compressed/misc.c
@@ -169,7 +169,7 @@ void __puthex(unsigned long value)
 }
 
 #if CONFIG_X86_NEED_RELOCS
-static void handle_relocations(void *output, unsigned long output_len,
+void handle_relocations(void *output, unsigned long output_len,
 			       unsigned long virt_addr)
 {
 	int *reloc;
@@ -264,7 +264,7 @@ static inline void handle_relocations(void *output, unsigned long output_len,
 { }
 #endif
 
-static void parse_elf(void *output)
+void parse_elf(void *output)
 {
 #ifdef CONFIG_X86_64
 	Elf64_Ehdr ehdr;
diff --git a/arch/x86/boot/compressed/pagetable.c b/arch/x86/boot/compressed/pagetable.c
index 28029be..a916e6f 100644
--- a/arch/x86/boot/compressed/pagetable.c
+++ b/arch/x86/boot/compressed/pagetable.c
@@ -40,7 +40,7 @@ struct alloc_pgt_data {
  * above. Besides the local callers, this is used as the allocation
  * callback in mapping_info below.
  */
-static void *alloc_pgt_page(void *context)
+void *alloc_pgt_page(void *context)
 {
 	struct alloc_pgt_data *pages = (struct alloc_pgt_data *)context;
 	unsigned char *entry;
diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
index c8b3987..738b3e0 100644
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -73,7 +73,7 @@ void __init setup_cpu_local_masks(void)
 	alloc_bootmem_cpumask_var(&cpu_sibling_setup_mask);
 }
 
-static void default_init(struct cpuinfo_x86 *c)
+void default_init(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_X86_64
 	cpu_detect_cache_sizes(c);
@@ -152,7 +152,7 @@ DEFINE_PER_CPU_PAGE_ALIGNED(struct gdt_page, gdt_page) = { .gdt = {
 } };
 EXPORT_PER_CPU_SYMBOL_GPL(gdt_page);
 
-static int __init x86_mpx_setup(char *s)
+int __init x86_mpx_setup(char *s)
 {
 	/* require an exact match without trailing characters */
 	if (strlen(s))
@@ -168,7 +168,7 @@ static int __init x86_mpx_setup(char *s)
 }
 __setup("nompx", x86_mpx_setup);
 
-static int __init x86_noinvpcid_setup(char *s)
+int __init x86_noinvpcid_setup(char *s)
 {
 	/* noinvpcid doesn't accept parameters */
 	if (s)
@@ -188,14 +188,14 @@ early_param("noinvpcid", x86_noinvpcid_setup);
 static int cachesize_override = -1;
 static int disable_x86_serial_nr = 1;
 
-static int __init cachesize_setup(char *str)
+int __init cachesize_setup(char *str)
 {
 	get_option(&str, &cachesize_override);
 	return 1;
 }
 __setup("cachesize=", cachesize_setup);
 
-static int __init x86_sep_setup(char *s)
+int __init x86_sep_setup(char *s)
 {
 	setup_clear_cpu_cap(X86_FEATURE_SEP);
 	return 1;
@@ -203,7 +203,7 @@ static int __init x86_sep_setup(char *s)
 __setup("nosep", x86_sep_setup);
 
 /* Standard macro to see if a specific flag is changeable */
-static inline int flag_is_changeable_p(u32 flag)
+int flag_is_changeable_p(u32 flag)
 {
 	u32 f1, f2;
 
@@ -237,7 +237,7 @@ int have_cpuid_p(void)
 	return flag_is_changeable_p(X86_EFLAGS_ID);
 }
 
-static void squash_the_stupid_serial_number(struct cpuinfo_x86 *c)
+void squash_the_stupid_serial_number(struct cpuinfo_x86 *c)
 {
 	unsigned long lo, hi;
 
@@ -257,23 +257,23 @@ static void squash_the_stupid_serial_number(struct cpuinfo_x86 *c)
 	c->cpuid_level = cpuid_eax(0);
 }
 
-static int __init x86_serial_nr_setup(char *s)
+int __init x86_serial_nr_setup(char *s)
 {
 	disable_x86_serial_nr = 0;
 	return 1;
 }
 __setup("serialnumber", x86_serial_nr_setup);
 #else
-static inline int flag_is_changeable_p(u32 flag)
+int flag_is_changeable_p(u32 flag)
 {
 	return 1;
 }
-static inline void squash_the_stupid_serial_number(struct cpuinfo_x86 *c)
+void squash_the_stupid_serial_number(struct cpuinfo_x86 *c)
 {
 }
 #endif
 
-static __init int setup_disable_smep(char *arg)
+_init int setup_disable_smep(char *arg)
 {
 	setup_clear_cpu_cap(X86_FEATURE_SMEP);
 	/* Check for things that depend on SMEP being enabled: */
@@ -282,20 +282,20 @@ static __init int setup_disable_smep(char *arg)
 }
 __setup("nosmep", setup_disable_smep);
 
-static __always_inline void setup_smep(struct cpuinfo_x86 *c)
+void setup_smep(struct cpuinfo_x86 *c)
 {
 	if (cpu_has(c, X86_FEATURE_SMEP))
 		cr4_set_bits(X86_CR4_SMEP);
 }
 
-static __init int setup_disable_smap(char *arg)
+__init int setup_disable_smap(char *arg)
 {
 	setup_clear_cpu_cap(X86_FEATURE_SMAP);
 	return 1;
 }
 __setup("nosmap", setup_disable_smap);
 
-static __always_inline void setup_smap(struct cpuinfo_x86 *c)
+void setup_smap(struct cpuinfo_x86 *c)
 {
 	unsigned long eflags = native_save_fl();
 
@@ -316,7 +316,7 @@ static __always_inline void setup_smap(struct cpuinfo_x86 *c)
  */
 static bool pku_disabled;
 
-static __always_inline void setup_pku(struct cpuinfo_x86 *c)
+void setup_pku(struct cpuinfo_x86 *c)
 {
 	/* check the boot processor, plus compile options for PKU: */
 	if (!cpu_feature_enabled(X86_FEATURE_PKU))
@@ -337,7 +337,7 @@ static __always_inline void setup_pku(struct cpuinfo_x86 *c)
 }
 
 #ifdef CONFIG_X86_INTEL_MEMORY_PROTECTION_KEYS
-static __init int setup_disable_pku(char *arg)
+__init int setup_disable_pku(char *arg)
 {
 	/*
 	 * Do not clear the X86_FEATURE_PKU bit.  All of the
@@ -375,7 +375,7 @@ cpuid_dependent_features[] = {
 	{ 0, 0 }
 };
 
-static void filter_cpuid_features(struct cpuinfo_x86 *c, bool warn)
+void filter_cpuid_features(struct cpuinfo_x86 *c, bool warn)
 {
 	const struct cpuid_dependent_feature *df;
 
@@ -412,7 +412,7 @@ static void filter_cpuid_features(struct cpuinfo_x86 *c, bool warn)
  */
 
 /* Look up CPU names by table lookup. */
-static const char *table_lookup_model(struct cpuinfo_x86 *c)
+const char *table_lookup_model(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_X86_32
 	const struct legacy_cpu_model_info *info;
@@ -449,7 +449,7 @@ void load_percpu_segment(int cpu)
 }
 
 /* Setup the fixmap mapping only once per-processor */
-static inline void setup_fixmap_gdt(int cpu)
+void setup_fixmap_gdt(int cpu)
 {
 #ifdef CONFIG_X86_64
 	/* On 64-bit systems, we use a read-only fixmap GDT. */
@@ -507,7 +507,7 @@ void switch_to_new_gdt(int cpu)
 
 static const struct cpu_dev *cpu_devs[X86_VENDOR_NUM] = {};
 
-static void get_model_name(struct cpuinfo_x86 *c)
+void get_model_name(struct cpuinfo_x86 *c)
 {
 	unsigned int *v;
 	char *p, *q, *s;
@@ -585,7 +585,7 @@ u16 __read_mostly tlb_lld_2m[NR_INFO];
 u16 __read_mostly tlb_lld_4m[NR_INFO];
 u16 __read_mostly tlb_lld_1g[NR_INFO];
 
-static void cpu_detect_tlb(struct cpuinfo_x86 *c)
+void cpu_detect_tlb(struct cpuinfo_x86 *c)
 {
 	if (this_cpu->c_detect_tlb)
 		this_cpu->c_detect_tlb(c);
@@ -650,7 +650,7 @@ void detect_ht(struct cpuinfo_x86 *c)
 #endif
 }
 
-static void get_cpu_vendor(struct cpuinfo_x86 *c)
+void get_cpu_vendor(struct cpuinfo_x86 *c)
 {
 	char *v = c->x86_vendor_id;
 	int i;
@@ -701,7 +701,7 @@ void cpu_detect(struct cpuinfo_x86 *c)
 	}
 }
 
-static void apply_forced_caps(struct cpuinfo_x86 *c)
+void apply_forced_caps(struct cpuinfo_x86 *c)
 {
 	int i;
 
@@ -813,7 +813,7 @@ void get_cpu_cap(struct cpuinfo_x86 *c)
 	apply_forced_caps(c);
 }
 
-static void identify_cpu_without_cpuid(struct cpuinfo_x86 *c)
+void identify_cpu_without_cpuid(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_X86_32
 	int i;
@@ -848,7 +848,7 @@ static void identify_cpu_without_cpuid(struct cpuinfo_x86 *c)
  * WARNING: this function is only called on the BP.  Don't add code here
  * that is supposed to run on all CPUs.
  */
-static void __init early_identify_cpu(struct cpuinfo_x86 *c)
+void __init early_identify_cpu(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_X86_64
 	c->x86_clflush_size = 64;
@@ -930,7 +930,7 @@ void __init early_cpu_init(void)
  * unless we can find a reliable way to detect all the broken cases.
  * Enable it explicitly on 64-bit for non-constant inputs of cpu_has().
  */
-static void detect_nopl(struct cpuinfo_x86 *c)
+void detect_nopl(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_X86_32
 	clear_cpu_cap(c, X86_FEATURE_NOPL);
@@ -939,7 +939,7 @@ static void detect_nopl(struct cpuinfo_x86 *c)
 #endif
 }
 
-static void detect_null_seg_behavior(struct cpuinfo_x86 *c)
+void detect_null_seg_behavior(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_X86_64
 	/*
@@ -968,7 +968,7 @@ static void detect_null_seg_behavior(struct cpuinfo_x86 *c)
 #endif
 }
 
-static void generic_identify(struct cpuinfo_x86 *c)
+void generic_identify(struct cpuinfo_x86 *c)
 {
 	c->extended_cpuid_level = 0;
 
@@ -1029,7 +1029,7 @@ static void generic_identify(struct cpuinfo_x86 *c)
 #endif
 }
 
-static void x86_init_cache_qos(struct cpuinfo_x86 *c)
+void x86_init_cache_qos(struct cpuinfo_x86 *c)
 {
 	/*
 	 * The heavy lifting of max_rmid and cache_occ_scale are handled
@@ -1047,7 +1047,7 @@ static void x86_init_cache_qos(struct cpuinfo_x86 *c)
  * Validate that ACPI/mptables have the same information about the
  * effective APIC id and update the package map.
  */
-static void validate_apic_and_package_id(struct cpuinfo_x86 *c)
+void validate_apic_and_package_id(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_SMP
 	unsigned int apicid, cpu = smp_processor_id();
@@ -1067,7 +1067,7 @@ static void validate_apic_and_package_id(struct cpuinfo_x86 *c)
 /*
  * This does the hard work of actually picking apart the CPU stuff...
  */
-static void identify_cpu(struct cpuinfo_x86 *c)
+void identify_cpu(struct cpuinfo_x86 *c)
 {
 	int i;
 
@@ -1240,7 +1240,7 @@ void identify_secondary_cpu(struct cpuinfo_x86 *c)
 	validate_apic_and_package_id(c);
 }
 
-static __init int setup_noclflush(char *arg)
+__init int setup_noclflush(char *arg)
 {
 	setup_clear_cpu_cap(X86_FEATURE_CLFLUSH);
 	setup_clear_cpu_cap(X86_FEATURE_CLFLUSHOPT);
@@ -1275,7 +1275,7 @@ void print_cpu_info(struct cpuinfo_x86 *c)
 		pr_cont(")\n");
 }
 
-static __init int setup_disablecpuid(char *arg)
+__init int setup_disablecpuid(char *arg)
 {
 	int bit;
 
@@ -1421,7 +1421,7 @@ DEFINE_PER_CPU_ALIGNED(struct stack_canary, stack_canary);
 /*
  * Clear all 6 debug registers:
  */
-static void clear_all_debug_regs(void)
+void clear_all_debug_regs(void)
 {
 	int i;
 
@@ -1439,7 +1439,7 @@ static void clear_all_debug_regs(void)
  * Restore debug regs if using kgdbwait and you have a kernel debugger
  * connection established.
  */
-static void dbg_restore_debug_regs(void)
+void dbg_restore_debug_regs(void)
 {
 	if (unlikely(kgdb_connected && arch_kgdb_ops.correct_hw_break))
 		arch_kgdb_ops.correct_hw_break();
@@ -1448,7 +1448,7 @@ static void dbg_restore_debug_regs(void)
 #define dbg_restore_debug_regs()
 #endif /* ! CONFIG_KGDB */
 
-static void wait_for_master_cpu(int cpu)
+void wait_for_master_cpu(int cpu)
 {
 #ifdef CONFIG_SMP
 	/*
@@ -1630,7 +1630,7 @@ void cpu_init(void)
 }
 #endif
 
-static void bsp_resume(void)
+void bsp_resume(void)
 {
 	if (this_cpu->c_bsp_resume)
 		this_cpu->c_bsp_resume(&boot_cpu_data);
@@ -1640,7 +1640,7 @@ static struct syscore_ops cpu_syscore_ops = {
 	.resume		= bsp_resume,
 };
 
-static int __init init_cpu_syscore(void)
+int __init init_cpu_syscore(void)
 {
 	register_syscore_ops(&cpu_syscore_ops);
 	return 0;
diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c
index dfa90a3..94fda16 100644
--- a/arch/x86/kernel/cpu/intel.c
+++ b/arch/x86/kernel/cpu/intel.c
@@ -36,7 +36,7 @@
  */
 static int forcempx;
 
-static int __init forcempx_setup(char *__unused)
+int __init forcempx_setup(char *__unused)
 {
 	forcempx = 1;
 
@@ -67,14 +67,14 @@ void check_mpx_erratum(struct cpuinfo_x86 *c)
 
 static bool ring3mwait_disabled __read_mostly;
 
-static int __init ring3mwait_disable(char *__unused)
+int __init ring3mwait_disable(char *__unused)
 {
 	ring3mwait_disabled = true;
 	return 0;
 }
 __setup("ring3mwait=disable", ring3mwait_disable);
 
-static void probe_xeon_phi_r3mwait(struct cpuinfo_x86 *c)
+void probe_xeon_phi_r3mwait(struct cpuinfo_x86 *c)
 {
 	/*
 	 * Ring 3 MONITOR/MWAIT feature cannot be detected without
@@ -101,7 +101,7 @@ static void probe_xeon_phi_r3mwait(struct cpuinfo_x86 *c)
 		ELF_HWCAP2 |= HWCAP2_RING3MWAIT;
 }
 
-static void early_init_intel(struct cpuinfo_x86 *c)
+void early_init_intel(struct cpuinfo_x86 *c)
 {
 	u64 misc_enable;
 
@@ -265,7 +265,7 @@ int ppro_with_ram_bug(void)
 	return 0;
 }
 
-static void intel_smp_check(struct cpuinfo_x86 *c)
+void intel_smp_check(struct cpuinfo_x86 *c)
 {
 	/* calling is from identify_secondary_cpu() ? */
 	if (!c->cpu_index)
@@ -286,14 +286,14 @@ static void intel_smp_check(struct cpuinfo_x86 *c)
 }
 
 static int forcepae;
-static int __init forcepae_setup(char *__unused)
+int __init forcepae_setup(char *__unused)
 {
 	forcepae = 1;
 	return 1;
 }
 __setup("forcepae", forcepae_setup);
 
-static void intel_workarounds(struct cpuinfo_x86 *c)
+void intel_workarounds(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_X86_F00F_BUG
 	/*
@@ -376,12 +376,12 @@ static void intel_workarounds(struct cpuinfo_x86 *c)
 	intel_smp_check(c);
 }
 #else
-static void intel_workarounds(struct cpuinfo_x86 *c)
+void intel_workarounds(struct cpuinfo_x86 *c)
 {
 }
 #endif
 
-static void srat_detect_node(struct cpuinfo_x86 *c)
+void srat_detect_node(struct cpuinfo_x86 *c)
 {
 #ifdef CONFIG_NUMA
 	unsigned node;
@@ -401,7 +401,7 @@ static void srat_detect_node(struct cpuinfo_x86 *c)
 /*
  * find out the number of processor cores on the die
  */
-static int intel_num_cpu_cores(struct cpuinfo_x86 *c)
+int intel_num_cpu_cores(struct cpuinfo_x86 *c)
 {
 	unsigned int eax, ebx, ecx, edx;
 
@@ -416,7 +416,7 @@ static int intel_num_cpu_cores(struct cpuinfo_x86 *c)
 		return 1;
 }
 
-static void detect_vmx_virtcap(struct cpuinfo_x86 *c)
+void detect_vmx_virtcap(struct cpuinfo_x86 *c)
 {
 	/* Intel VMX MSR indicated features */
 #define X86_VMX_FEATURE_PROC_CTLS_TPR_SHADOW	0x00200000
@@ -454,7 +454,7 @@ static void detect_vmx_virtcap(struct cpuinfo_x86 *c)
 	}
 }
 
-static void init_intel_energy_perf(struct cpuinfo_x86 *c)
+void init_intel_energy_perf(struct cpuinfo_x86 *c)
 {
 	u64 epb;
 
@@ -475,7 +475,7 @@ static void init_intel_energy_perf(struct cpuinfo_x86 *c)
 	wrmsrl(MSR_IA32_ENERGY_PERF_BIAS, epb);
 }
 
-static void intel_bsp_resume(struct cpuinfo_x86 *c)
+void intel_bsp_resume(struct cpuinfo_x86 *c)
 {
 	/*
 	 * MSR_IA32_ENERGY_PERF_BIAS is lost across suspend/resume,
@@ -484,7 +484,7 @@ static void intel_bsp_resume(struct cpuinfo_x86 *c)
 	init_intel_energy_perf(c);
 }
 
-static void init_cpuid_fault(struct cpuinfo_x86 *c)
+void init_cpuid_fault(struct cpuinfo_x86 *c)
 {
 	u64 msr;
 
@@ -494,7 +494,7 @@ static void init_cpuid_fault(struct cpuinfo_x86 *c)
 	}
 }
 
-static void init_intel_misc_features(struct cpuinfo_x86 *c)
+void init_intel_misc_features(struct cpuinfo_x86 *c)
 {
 	u64 msr;
 
@@ -512,7 +512,7 @@ static void init_intel_misc_features(struct cpuinfo_x86 *c)
 	wrmsrl(MSR_MISC_FEATURES_ENABLES, msr);
 }
 
-static void init_intel(struct cpuinfo_x86 *c)
+void init_intel(struct cpuinfo_x86 *c)
 {
 	unsigned int l2 = 0;
 
@@ -630,7 +630,7 @@ static void init_intel(struct cpuinfo_x86 *c)
 }
 
 #ifdef CONFIG_X86_32
-static unsigned int intel_size_cache(struct cpuinfo_x86 *c, unsigned int size)
+unsigned int intel_size_cache(struct cpuinfo_x86 *c, unsigned int size)
 {
 	/*
 	 * Intel PIII Tualatin. This comes in two flavours.
@@ -709,7 +709,7 @@ static const struct _tlb_table intel_tlb_table[] = {
 	{ 0x00, 0, 0 }
 };
 
-static void intel_tlb_lookup(const unsigned char desc)
+void intel_tlb_lookup(const unsigned char desc)
 {
 	unsigned char k;
 	if (desc == 0)
@@ -796,7 +796,7 @@ static void intel_tlb_lookup(const unsigned char desc)
 	}
 }
 
-static void intel_detect_tlb(struct cpuinfo_x86 *c)
+void intel_detect_tlb(struct cpuinfo_x86 *c)
 {
 	int i, j, n;
 	unsigned int regs[4];
diff --git a/arch/x86/kernel/head64.c b/arch/x86/kernel/head64.c
index 9ba7954..46bdf0a 100644
--- a/arch/x86/kernel/head64.c
+++ b/arch/x86/kernel/head64.c
@@ -143,7 +143,7 @@ void __head __startup_64(unsigned long physaddr)
 }
 
 /* Wipe all early page tables except for the kernel symbol map */
-static void __init reset_early_page_tables(void)
+void __init reset_early_page_tables(void)
 {
 	memset(early_top_pgt, 0, sizeof(pgd_t)*(PTRS_PER_PGD-1));
 	next_early_pgt = 0;
@@ -224,13 +224,13 @@ int __init early_make_pgtable(unsigned long address)
 
 /* Don't add a printk in there. printk relies on the PDA which is not initialized 
    yet. */
-static void __init clear_bss(void)
+void __init clear_bss(void)
 {
 	memset(__bss_start, 0,
 	       (unsigned long) __bss_stop - (unsigned long) __bss_start);
 }
 
-static unsigned long get_cmd_line_ptr(void)
+unsigned long get_cmd_line_ptr(void)
 {
 	unsigned long cmd_line_ptr = boot_params.hdr.cmd_line_ptr;
 
@@ -239,7 +239,7 @@ static unsigned long get_cmd_line_ptr(void)
 	return cmd_line_ptr;
 }
 
-static void __init copy_bootdata(char *real_mode_data)
+void __init copy_bootdata(char *real_mode_data)
 {
 	char * command_line;
 	unsigned long cmd_line_ptr;
diff --git a/arch/x86/kernel/setup.c b/arch/x86/kernel/setup.c
index 3486d04..17e6408 100644
--- a/arch/x86/kernel/setup.c
+++ b/arch/x86/kernel/setup.c
@@ -247,7 +247,7 @@ EXPORT_SYMBOL(edd);
  *              from boot_params into a safe place.
  *
  */
-static inline void __init copy_edd(void)
+void __init copy_edd(void)
 {
      memcpy(edd.mbr_signature, boot_params.edd_mbr_sig_buffer,
 	    sizeof(edd.mbr_signature));
@@ -256,7 +256,7 @@ static inline void __init copy_edd(void)
      edd.edd_info_nr = boot_params.eddbuf_entries;
 }
 #else
-static inline void __init copy_edd(void)
+void __init copy_edd(void)
 {
 }
 #endif
@@ -281,12 +281,12 @@ void * __init extend_brk(size_t size, size_t align)
 }
 
 #ifdef CONFIG_X86_32
-static void __init cleanup_highmap(void)
+void __init cleanup_highmap(void)
 {
 }
 #endif
 
-static void __init reserve_brk(void)
+void __init reserve_brk(void)
 {
 	if (_brk_end > _brk_start)
 		memblock_reserve(__pa_symbol(_brk_start),
@@ -301,7 +301,7 @@ u64 relocated_ramdisk;
 
 #ifdef CONFIG_BLK_DEV_INITRD
 
-static u64 __init get_ramdisk_image(void)
+u64 __init get_ramdisk_image(void)
 {
 	u64 ramdisk_image = boot_params.hdr.ramdisk_image;
 
@@ -309,7 +309,7 @@ static u64 __init get_ramdisk_image(void)
 
 	return ramdisk_image;
 }
-static u64 __init get_ramdisk_size(void)
+u64 __init get_ramdisk_size(void)
 {
 	u64 ramdisk_size = boot_params.hdr.ramdisk_size;
 
@@ -318,7 +318,7 @@ static u64 __init get_ramdisk_size(void)
 	return ramdisk_size;
 }
 
-static void __init relocate_initrd(void)
+void __init relocate_initrd(void)
 {
 	/* Assume only end is not page aligned */
 	u64 ramdisk_image = get_ramdisk_image();
@@ -349,7 +349,7 @@ static void __init relocate_initrd(void)
 		relocated_ramdisk, relocated_ramdisk + ramdisk_size - 1);
 }
 
-static void __init early_reserve_initrd(void)
+void __init early_reserve_initrd(void)
 {
 	/* Assume only end is not page aligned */
 	u64 ramdisk_image = get_ramdisk_image();
@@ -362,7 +362,7 @@ static void __init early_reserve_initrd(void)
 
 	memblock_reserve(ramdisk_image, ramdisk_end - ramdisk_image);
 }
-static void __init reserve_initrd(void)
+void __init reserve_initrd(void)
 {
 	/* Assume only end is not page aligned */
 	u64 ramdisk_image = get_ramdisk_image();
@@ -399,15 +399,15 @@ static void __init reserve_initrd(void)
 }
 
 #else
-static void __init early_reserve_initrd(void)
+void __init early_reserve_initrd(void)
 {
 }
-static void __init reserve_initrd(void)
+void __init reserve_initrd(void)
 {
 }
 #endif /* CONFIG_BLK_DEV_INITRD */
 
-static void __init parse_setup_data(void)
+void __init parse_setup_data(void)
 {
 	struct setup_data *data;
 	u64 pa_data, pa_next;
@@ -439,7 +439,7 @@ static void __init parse_setup_data(void)
 	}
 }
 
-static void __init memblock_x86_reserve_range_setup_data(void)
+void __init memblock_x86_reserve_range_setup_data(void)
 {
 	struct setup_data *data;
 	u64 pa_data;
@@ -475,7 +475,7 @@ static void __init memblock_x86_reserve_range_setup_data(void)
 # define CRASH_ADDR_HIGH_MAX	MAXMEM
 #endif
 
-static int __init reserve_crashkernel_low(void)
+int __init reserve_crashkernel_low(void)
 {
 #ifdef CONFIG_X86_64
 	unsigned long long base, low_base = 0, low_size = 0;
@@ -528,7 +528,7 @@ static int __init reserve_crashkernel_low(void)
 	return 0;
 }
 
-static void __init reserve_crashkernel(void)
+void __init reserve_crashkernel(void)
 {
 	unsigned long long crash_size, crash_base, total_mem;
 	bool high = false;
@@ -595,7 +595,7 @@ static void __init reserve_crashkernel(void)
 	insert_resource(&iomem_resource, &crashk_res);
 }
 #else
-static void __init reserve_crashkernel(void)
+void __init reserve_crashkernel(void)
 {
 }
 #endif
@@ -633,7 +633,7 @@ void __init reserve_standard_io_resources(void)
 
 }
 
-static __init void reserve_ibft_region(void)
+__init void reserve_ibft_region(void)
 {
 	unsigned long addr, size = 0;
 
@@ -643,7 +643,7 @@ static __init void reserve_ibft_region(void)
 		memblock_reserve(addr, size);
 }
 
-static bool __init snb_gfx_workaround_needed(void)
+bool __init snb_gfx_workaround_needed(void)
 {
 #ifdef CONFIG_PCI
 	int i;
@@ -679,7 +679,7 @@ static bool __init snb_gfx_workaround_needed(void)
  * Sandy Bridge graphics has trouble with certain ranges, exclude
  * them from allocation.
  */
-static void __init trim_snb_memory(void)
+void __init trim_snb_memory(void)
 {
 	static const __initconst unsigned long bad_pages[] = {
 		0x20050000,
@@ -715,12 +715,12 @@ static void __init trim_snb_memory(void)
  *
  * If this gets used more widely it could use a real dispatch mechanism.
  */
-static void __init trim_platform_memory_ranges(void)
+void __init trim_platform_memory_ranges(void)
 {
 	trim_snb_memory();
 }
 
-static void __init trim_bios_range(void)
+void __init trim_bios_range(void)
 {
 	/*
 	 * A special case is the first 4Kb of memory;
@@ -744,7 +744,7 @@ static void __init trim_bios_range(void)
 }
 
 /* called before trim_bios_range() to spare extra sanitize */
-static void __init e820_add_kernel_range(void)
+void __init e820_add_kernel_range(void)
 {
 	u64 start = __pa_symbol(_text);
 	u64 size = __pa_symbol(_end) - start;
@@ -766,7 +766,7 @@ static void __init e820_add_kernel_range(void)
 
 static unsigned reserve_low = CONFIG_X86_RESERVE_LOW << 10;
 
-static int __init parse_reservelow(char *p)
+int __init parse_reservelow(char *p)
 {
 	unsigned long long size;
 
@@ -788,7 +788,7 @@ static int __init parse_reservelow(char *p)
 
 early_param("reservelow", parse_reservelow);
 
-static void __init trim_low_memory_range(void)
+void __init trim_low_memory_range(void)
 {
 	memblock_reserve(0, ALIGN(reserve_low, PAGE_SIZE));
 }
@@ -796,7 +796,7 @@ static void __init trim_low_memory_range(void)
 /*
  * Dump out kernel offset information on panic.
  */
-static int
+int
 dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 {
 	if (kaslr_enabled()) {
@@ -812,7 +812,7 @@ dump_kernel_offset(struct notifier_block *self, unsigned long v, void *p)
 	return 0;
 }
 
-static void __init simple_udelay_calibration(void)
+void __init simple_udelay_calibration(void)
 {
 	unsigned int tsc_khz, cpu_khz;
 	unsigned long lpj;
@@ -1333,7 +1333,7 @@ static struct notifier_block kernel_offset_notifier = {
 	.notifier_call = dump_kernel_offset
 };
 
-static int __init register_kernel_offset_dumper(void)
+int __init register_kernel_offset_dumper(void)
 {
 	atomic_notifier_chain_register(&panic_notifier_list,
 					&kernel_offset_notifier);
diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c
index bf54309..d784672 100644
--- a/arch/x86/kernel/traps.c
+++ b/arch/x86/kernel/traps.c
@@ -85,13 +85,13 @@ gate_desc idt_table[NR_VECTORS] __page_aligned_bss;
 DECLARE_BITMAP(used_vectors, NR_VECTORS);
 EXPORT_SYMBOL_GPL(used_vectors);
 
-static inline void cond_local_irq_enable(struct pt_regs *regs)
+void cond_local_irq_enable(struct pt_regs *regs)
 {
 	if (regs->flags & X86_EFLAGS_IF)
 		local_irq_enable();
 }
 
-static inline void cond_local_irq_disable(struct pt_regs *regs)
+void cond_local_irq_disable(struct pt_regs *regs)
 {
 	if (regs->flags & X86_EFLAGS_IF)
 		local_irq_disable();
@@ -200,7 +200,7 @@ int fixup_bug(struct pt_regs *regs, int trapnr)
 	return 0;
 }
 
-static nokprobe_inline int
+int
 do_trap_no_signal(struct task_struct *tsk, int trapnr, char *str,
 		  struct pt_regs *regs,	long error_code)
 {
@@ -232,7 +232,7 @@ do_trap_no_signal(struct task_struct *tsk, int trapnr, char *str,
 	return -1;
 }
 
-static siginfo_t *fill_trap_info(struct pt_regs *regs, int signr, int trapnr,
+siginfo_t *fill_trap_info(struct pt_regs *regs, int signr, int trapnr,
 				siginfo_t *info)
 {
 	unsigned long siaddr;
@@ -263,7 +263,7 @@ static siginfo_t *fill_trap_info(struct pt_regs *regs, int signr, int trapnr,
 	return info;
 }
 
-static void
+void
 do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
 	long error_code, siginfo_t *info)
 {
@@ -297,7 +297,7 @@ do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
 }
 NOKPROBE_SYMBOL(do_trap);
 
-static void do_error_trap(struct pt_regs *regs, long error_code, char *str,
+void do_error_trap(struct pt_regs *regs, long error_code, char *str,
 			  unsigned long trapnr, int signr)
 {
 	siginfo_t info;
@@ -652,7 +652,7 @@ struct bad_iret_stack *fixup_bad_iret(struct bad_iret_stack *s)
 NOKPROBE_SYMBOL(fixup_bad_iret);
 #endif
 
-static bool is_sysenter_singlestep(struct pt_regs *regs)
+bool is_sysenter_singlestep(struct pt_regs *regs)
 {
 	/*
 	 * We don't try for precision here.  If we're anywhere in the region of
@@ -820,7 +820,7 @@ NOKPROBE_SYMBOL(do_debug);
  * the correct behaviour even in the presence of the asynchronous
  * IRQ13 behaviour
  */
-static void math_error(struct pt_regs *regs, int error_code, int trapnr)
+void math_error(struct pt_regs *regs, int error_code, int trapnr)
 {
 	struct task_struct *task = current;
 	struct fpu *fpu = &task->thread.fpu;
diff --git a/drivers/firmware/efi/libstub/arm-stub.c b/drivers/firmware/efi/libstub/arm-stub.c
index 8181ac1..27b061e9 100644
--- a/drivers/firmware/efi/libstub/arm-stub.c
+++ b/drivers/firmware/efi/libstub/arm-stub.c
@@ -74,7 +74,7 @@ void efi_char16_printk(efi_system_table_t *sys_table_arg,
 	out->output_string(out, str);
 }
 
-static struct screen_info *setup_graphics(efi_system_table_t *sys_table_arg)
+struct screen_info *setup_graphics(efi_system_table_t *sys_table_arg)
 {
 	efi_guid_t gop_proto = EFI_GRAPHICS_OUTPUT_PROTOCOL_GUID;
 	efi_status_t status;
diff --git a/drivers/firmware/efi/libstub/efi-stub-helper.c b/drivers/firmware/efi/libstub/efi-stub-helper.c
index b018436..94e6ea2 100644
--- a/drivers/firmware/efi/libstub/efi-stub-helper.c
+++ b/drivers/firmware/efi/libstub/efi-stub-helper.c
@@ -68,7 +68,7 @@ void efi_printk(efi_system_table_t *sys_table_arg, char *str)
 	}
 }
 
-static inline bool mmap_has_headroom(unsigned long buff_size,
+bool mmap_has_headroom(unsigned long buff_size,
 				     unsigned long map_size,
 				     unsigned long desc_size)
 {
@@ -721,7 +721,7 @@ efi_status_t efi_relocate_kernel(efi_system_table_t *sys_table_arg,
  * Get the number of UTF-8 bytes corresponding to an UTF-16 character.
  * This overestimates for surrogates, but that is okay.
  */
-static int efi_utf8_bytes(u16 c)
+int efi_utf8_bytes(u16 c)
 {
 	return 1 + (c >= 0x80) + (c >= 0x800);
 }
@@ -729,7 +729,7 @@ static int efi_utf8_bytes(u16 c)
 /*
  * Convert an UTF-16 string, not necessarily null terminated, to UTF-8.
  */
-static u8 *efi_utf16_to_utf8(u8 *dst, const u16 *src, int n)
+u8 *efi_utf16_to_utf8(u8 *dst, const u16 *src, int n)
 {
 	unsigned int c;
 
diff --git a/drivers/firmware/efi/libstub/gop.c b/drivers/firmware/efi/libstub/gop.c
index 24c461d..958dc8f 100644
--- a/drivers/firmware/efi/libstub/gop.c
+++ b/drivers/firmware/efi/libstub/gop.c
@@ -12,7 +12,7 @@
 #include <asm/efi.h>
 #include <asm/setup.h>
 
-static void find_bits(unsigned long mask, u8 *pos, u8 *size)
+void find_bits(unsigned long mask, u8 *pos, u8 *size)
 {
 	u8 first, len;
 
@@ -35,7 +35,7 @@ static void find_bits(unsigned long mask, u8 *pos, u8 *size)
 	*size = len;
 }
 
-static void
+void
 setup_pixel_info(struct screen_info *si, u32 pixels_per_scan_line,
 		 struct efi_pixel_bitmask pixel_info, int pixel_format)
 {
@@ -85,7 +85,7 @@ setup_pixel_info(struct screen_info *si, u32 pixels_per_scan_line,
 	}
 }
 
-static efi_status_t
+efi_status_t
 __gop_query32(efi_system_table_t *sys_table_arg,
 	      struct efi_graphics_output_protocol_32 *gop32,
 	      struct efi_graphics_output_mode_info **info,
@@ -109,7 +109,7 @@ __gop_query32(efi_system_table_t *sys_table_arg,
 	return status;
 }
 
-static efi_status_t
+efi_status_t
 setup_gop32(efi_system_table_t *sys_table_arg, struct screen_info *si,
             efi_guid_t *proto, unsigned long size, void **gop_handle)
 {
@@ -203,7 +203,7 @@ setup_gop32(efi_system_table_t *sys_table_arg, struct screen_info *si,
 	return status;
 }
 
-static efi_status_t
+efi_status_t
 __gop_query64(efi_system_table_t *sys_table_arg,
 	      struct efi_graphics_output_protocol_64 *gop64,
 	      struct efi_graphics_output_mode_info **info,
@@ -227,7 +227,7 @@ __gop_query64(efi_system_table_t *sys_table_arg,
 	return status;
 }
 
-static efi_status_t
+efi_status_t
 setup_gop64(efi_system_table_t *sys_table_arg, struct screen_info *si,
 	    efi_guid_t *proto, unsigned long size, void **gop_handle)
 {
diff --git a/init/main.c b/init/main.c
index 052481f..71fbf54 100644
--- a/init/main.c
+++ b/init/main.c
@@ -95,7 +95,7 @@
 #include <asm/sections.h>
 #include <asm/cacheflush.h>
 
-static int kernel_init(void *);
+int kernel_init(void *);
 
 extern void init_IRQ(void);
 extern void fork_init(void);
@@ -154,7 +154,7 @@ EXPORT_SYMBOL_GPL(static_key_initialized);
 unsigned int reset_devices;
 EXPORT_SYMBOL(reset_devices);
 
-static int __init set_reset_devices(char *str)
+int __init set_reset_devices(char *str)
 {
 	reset_devices = 1;
 	return 1;
@@ -168,7 +168,7 @@ static const char *panic_later, *panic_param;
 
 extern const struct obs_kernel_param __setup_start[], __setup_end[];
 
-static bool __init obsolete_checksetup(char *line)
+bool __init obsolete_checksetup(char *line)
 {
 	const struct obs_kernel_param *p;
 	bool had_early_param = false;
@@ -204,13 +204,13 @@ static bool __init obsolete_checksetup(char *line)
 unsigned long loops_per_jiffy = (1<<12);
 EXPORT_SYMBOL(loops_per_jiffy);
 
-static int __init debug_kernel(char *str)
+int __init debug_kernel(char *str)
 {
 	console_loglevel = CONSOLE_LOGLEVEL_DEBUG;
 	return 0;
 }
 
-static int __init quiet_kernel(char *str)
+int __init quiet_kernel(char *str)
 {
 	console_loglevel = CONSOLE_LOGLEVEL_QUIET;
 	return 0;
@@ -219,7 +219,7 @@ static int __init quiet_kernel(char *str)
 early_param("debug", debug_kernel);
 early_param("quiet", quiet_kernel);
 
-static int __init loglevel(char *str)
+int __init loglevel(char *str)
 {
 	int newlevel;
 
@@ -239,7 +239,7 @@ static int __init loglevel(char *str)
 early_param("loglevel", loglevel);
 
 /* Change NUL term back to "=", to make "param" the whole string. */
-static int __init repair_env_string(char *param, char *val,
+int __init repair_env_string(char *param, char *val,
 				    const char *unused, void *arg)
 {
 	if (val) {
@@ -257,7 +257,7 @@ static int __init repair_env_string(char *param, char *val,
 }
 
 /* Anything after -- gets handed straight to init. */
-static int __init set_init_arg(char *param, char *val,
+int __init set_init_arg(char *param, char *val,
 			       const char *unused, void *arg)
 {
 	unsigned int i;
@@ -282,7 +282,7 @@ static int __init set_init_arg(char *param, char *val,
  * Unknown boot options get handed to init, unless they look like
  * unused parameters (modprobe will find them in /proc/cmdline).
  */
-static int __init unknown_bootoption(char *param, char *val,
+int __init unknown_bootoption(char *param, char *val,
 				     const char *unused, void *arg)
 {
 	repair_env_string(param, val, unused, NULL);
@@ -324,7 +324,7 @@ static int __init unknown_bootoption(char *param, char *val,
 	return 0;
 }
 
-static int __init init_setup(char *str)
+int __init init_setup(char *str)
 {
 	unsigned int i;
 
@@ -341,7 +341,7 @@ static int __init init_setup(char *str)
 }
 __setup("init=", init_setup);
 
-static int __init rdinit_setup(char *str)
+int __init rdinit_setup(char *str)
 {
 	unsigned int i;
 
@@ -355,8 +355,8 @@ __setup("rdinit=", rdinit_setup);
 
 #ifndef CONFIG_SMP
 static const unsigned int setup_max_cpus = NR_CPUS;
-static inline void setup_nr_cpu_ids(void) { }
-static inline void smp_prepare_cpus(unsigned int maxcpus) { }
+void setup_nr_cpu_ids(void) { }
+void smp_prepare_cpus(unsigned int maxcpus) { }
 #endif
 
 /*
@@ -365,7 +365,7 @@ static inline void smp_prepare_cpus(unsigned int maxcpus) { }
  * parsing is performed in place, and we should allow a component to
  * store reference of name/value for future reference.
  */
-static void __init setup_command_line(char *command_line)
+void __init setup_command_line(char *command_line)
 {
 	saved_command_line =
 		memblock_virt_alloc(strlen(boot_command_line) + 1, 0);
@@ -387,7 +387,7 @@ static void __init setup_command_line(char *command_line)
 
 static __initdata DECLARE_COMPLETION(kthreadd_done);
 
-static noinline void __ref rest_init(void)
+void __ref rest_init(void)
 {
 	struct task_struct *tsk;
 	int pid;
@@ -437,7 +437,7 @@ static noinline void __ref rest_init(void)
 }
 
 /* Check for early params. */
-static int __init do_early_param(char *param, char *val,
+int __init do_early_param(char *param, char *val,
 				 const char *unused, void *arg)
 {
 	const struct obs_kernel_param *p;
@@ -491,7 +491,7 @@ void __init __weak thread_stack_cache_init(void)
 /*
  * Set up kernel memory allocators
  */
-static void __init mm_init(void)
+void __init mm_init(void)
 {
 	/*
 	 * page_ext requires contiguous pages,
@@ -702,7 +702,7 @@ asmlinkage __visible void __init start_kernel(void)
 }
 
 /* Call all constructor functions linked into the kernel. */
-static void __init do_ctors(void)
+void __init do_ctors(void)
 {
 #ifdef CONFIG_CONSTRUCTORS
 	ctor_fn_t *fn = (ctor_fn_t *) __ctors_start;
@@ -723,7 +723,7 @@ struct blacklist_entry {
 
 static __initdata_or_module LIST_HEAD(blacklisted_initcalls);
 
-static int __init initcall_blacklist(char *str)
+int __init initcall_blacklist(char *str)
 {
 	char *str_entry;
 	struct blacklist_entry *entry;
@@ -743,7 +743,7 @@ static int __init initcall_blacklist(char *str)
 	return 0;
 }
 
-static bool __init_or_module initcall_blacklisted(initcall_t fn)
+bool __init_or_module initcall_blacklisted(initcall_t fn)
 {
 	struct blacklist_entry *entry;
 	char fn_name[KSYM_SYMBOL_LEN];
@@ -771,20 +771,20 @@ static bool __init_or_module initcall_blacklisted(initcall_t fn)
 	return false;
 }
 #else
-static int __init initcall_blacklist(char *str)
+int __init initcall_blacklist(char *str)
 {
 	pr_warn("initcall_blacklist requires CONFIG_KALLSYMS\n");
 	return 0;
 }
 
-static bool __init_or_module initcall_blacklisted(initcall_t fn)
+bool __init_or_module initcall_blacklisted(initcall_t fn)
 {
 	return false;
 }
 #endif
 __setup("initcall_blacklist=", initcall_blacklist);
 
-static int __init_or_module do_one_initcall_debug(initcall_t fn)
+int __init_or_module do_one_initcall_debug(initcall_t fn)
 {
 	ktime_t calltime, delta, rettime;
 	unsigned long long duration;
@@ -868,7 +868,7 @@ static char *initcall_level_names[] __initdata = {
 	"late",
 };
 
-static void __init do_initcall_level(int level)
+void __init do_initcall_level(int level)
 {
 	initcall_t *fn;
 
@@ -883,7 +883,7 @@ static void __init do_initcall_level(int level)
 		do_one_initcall(*fn);
 }
 
-static void __init do_initcalls(void)
+void __init do_initcalls(void)
 {
 	int level;
 
@@ -898,7 +898,7 @@ static void __init do_initcalls(void)
  *
  * Now we can finally start doing some real work..
  */
-static void __init do_basic_setup(void)
+void __init do_basic_setup(void)
 {
 	cpuset_init_smp();
 	shmem_init();
@@ -909,7 +909,7 @@ static void __init do_basic_setup(void)
 	do_initcalls();
 }
 
-static void __init do_pre_smp_initcalls(void)
+void __init do_pre_smp_initcalls(void)
 {
 	initcall_t *fn;
 
@@ -928,7 +928,7 @@ void __init load_default_modules(void)
 	load_default_elevator_module();
 }
 
-static int run_init_process(const char *init_filename)
+int run_init_process(const char *init_filename)
 {
 	argv_init[0] = init_filename;
 	return do_execve(getname_kernel(init_filename),
@@ -936,7 +936,7 @@ static int run_init_process(const char *init_filename)
 		(const char __user *const __user *)envp_init);
 }
 
-static int try_to_run_init_process(const char *init_filename)
+int try_to_run_init_process(const char *init_filename)
 {
 	int ret;
 
@@ -950,11 +950,11 @@ static int try_to_run_init_process(const char *init_filename)
 	return ret;
 }
 
-static noinline void __init kernel_init_freeable(void);
+void __init kernel_init_freeable(void);
 
 #if defined(CONFIG_STRICT_KERNEL_RWX) || defined(CONFIG_STRICT_MODULE_RWX)
 bool rodata_enabled __ro_after_init = true;
-static int __init set_debug_rodata(char *str)
+int __init set_debug_rodata(char *str)
 {
 	return strtobool(str, &rodata_enabled);
 }
@@ -962,7 +962,7 @@ __setup("rodata=", set_debug_rodata);
 #endif
 
 #ifdef CONFIG_STRICT_KERNEL_RWX
-static void mark_readonly(void)
+void mark_readonly(void)
 {
 	if (rodata_enabled) {
 		mark_rodata_ro();
@@ -971,13 +971,13 @@ static void mark_readonly(void)
 		pr_info("Kernel memory protection disabled.\n");
 }
 #else
-static inline void mark_readonly(void)
+void mark_readonly(void)
 {
 	pr_warn("This architecture does not have kernel memory protection.\n");
 }
 #endif
 
-static int __ref kernel_init(void *unused)
+int __ref kernel_init(void *unused)
 {
 	int ret;
 
@@ -1023,7 +1023,7 @@ static int __ref kernel_init(void *unused)
 	      "See Linux Documentation/admin-guide/init.rst for guidance.");
 }
 
-static noinline void __init kernel_init_freeable(void)
+void __init kernel_init_freeable(void)
 {
 	/*
 	 * Wait until kthreadd is all set-up.
diff --git a/lib/decompress_inflate.c b/lib/decompress_inflate.c
index 555c06b..aa0d8cc 100644
--- a/lib/decompress_inflate.c
+++ b/lib/decompress_inflate.c
@@ -193,7 +193,7 @@ STATIC int INIT gunzip(unsigned char *buf, long len,
 	return __gunzip(buf, len, fill, flush, out_buf, 0, pos, error);
 }
 #else
-STATIC int INIT __decompress(unsigned char *buf, long len,
+int __decompress(unsigned char *buf, long len,
 			   long (*fill)(void*, unsigned long),
 			   long (*flush)(void*, unsigned long),
 			   unsigned char *out_buf, long out_len,
